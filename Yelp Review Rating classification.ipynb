{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import re\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_subset(num_stars):\n",
    "    dirname = str(num_stars)+'star'\n",
    "    reviews = []\n",
    "    i = 0\n",
    "    filectr = 0\n",
    "    with open('../yelp_academic_dataset_review.json') as f:\n",
    "        for line in f:\n",
    "            review = json.loads(line)\n",
    "            if review['stars'] == num_stars:\n",
    "                reviews.append(review)\n",
    "                i += 1\n",
    "            if i == 25000:\n",
    "                with open(dirname+'/reviews-subset-'+str(filectr)+'.pkl','w') as fw:\n",
    "                    pickle.dump(reviews,fw)\n",
    "                reviews = []\n",
    "                filectr += 1\n",
    "                i = 0\n",
    "        with open(dirname+'/reviews-subset-'+str(filectr)+'.pkl','w') as fw:\n",
    "            pickle.dump(reviews,fw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_subset(1)\n",
    "create_subset(2)\n",
    "create_subset(3)\n",
    "create_subset(4)\n",
    "create_subset(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "class Reviews(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.reviews = pickle.load(open(filename,'r'))\n",
    "\n",
    "    def __iter__(self):\n",
    "        for uid, review in enumerate(self.reviews):\n",
    "            #clean_review = clean_str(review['text'])\n",
    "            yield LabeledSentence(words=review['text'].split(), tags=['REV_%s_%s' % (review['stars'] , uid) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = Reviews('1star/reviews-subset-0.pkl')\n",
    "docmodel_1star = gensim.models.Doc2Vec(reviews, size=100, window=8, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews1 = Reviews('2star/reviews-subset-0.pkl')\n",
    "docmodel_2star = gensim.models.Doc2Vec(reviews, size=100, window=8, min_count=5, workers=4)\n",
    "reviews = Reviews('3star/reviews-subset-0.pkl')\n",
    "docmodel_3star = gensim.models.Doc2Vec(reviews, size=100, window=8, min_count=5, workers=4)\n",
    "reviews1 = Reviews('4star/reviews-subset-0.pkl')\n",
    "docmodel_4star = gensim.models.Doc2Vec(reviews, size=100, window=8, min_count=5, workers=4)\n",
    "reviews = Reviews('5star/reviews-subset-0.pkl')\n",
    "docmodel_5star = gensim.models.Doc2Vec(reviews, size=100, window=8, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docmodel_1star.save('1star/model-for-file-0.mdl')\n",
    "docmodel_2star.save('2star/model-for-file-0.mdl')\n",
    "docmodel_3star.save('3star/model-for-file-0.mdl')\n",
    "docmodel_4star.save('4star/model-for-file-0.mdl')\n",
    "docmodel_5star.save('5star/model-for-file-0.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docmodel_1star = gensim.models.Doc2Vec.load('1star/model-for-file-0.mdl')\n",
    "docmodel_2star = gensim.models.Doc2Vec.load('2star/model-for-file-0.mdl')\n",
    "docmodel_3star = gensim.models.Doc2Vec.load('3star/model-for-file-0.mdl')\n",
    "docmodel_4star = gensim.models.Doc2Vec.load('4star/model-for-file-0.mdl')\n",
    "docmodel_5star = gensim.models.Doc2Vec.load('5star/model-for-file-0.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [docmodel_1star,docmodel_2star,docmodel_3star,docmodel_4star,docmodel_5star]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21521"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docmodel_5star.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sentences = pickle.load(open('test-sentences.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sentence splitter\n",
    "alteos = re.compile(r'([!\\?])')\n",
    "def sentences(l):\n",
    "    l = alteos.sub(r' \\1 .', l).rstrip(\"(\\.)*\\n\")\n",
    "    return l.split(\".\")\n",
    "\n",
    "docs = [sentences(test_sent) for test_sent in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def docprob(docs, mods):\n",
    "    # score() takes a list [s] of sentences here; could also be a sentence generator\n",
    "    sentlist = [s for d in docs for s in d]\n",
    "    # the log likelihood of each sentence in this review under each w2v representation\n",
    "    llhd = np.array( [ m.score(sentlist, len(sentlist)) for m in mods ] )\n",
    "    # now exponentiate to get likelihoods, \n",
    "    lhd = np.exp(llhd - llhd.max(axis=0)) # subtract row max to avoid numeric overload\n",
    "    # normalize across models (stars) to get sentence-star probabilities\n",
    "    prob = pd.DataFrame( (lhd/lhd.sum(axis=0)).transpose() )\n",
    "    # and finally average the sentence probabilities to get the review probability\n",
    "    prob[\"doc\"] = [i for i,d in enumerate(docs) for s in d]\n",
    "    prob = prob.groupby(\"doc\").mean()\n",
    "    return prob\n",
    "\n",
    "prob = docprob(docs,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.98872757], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docmodel_5star.score('. '.join(docs[0]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
